import numpy as np
import torch

from kswap.module.unet import UNet2D
from dpipe.train.policy import Schedule
from dpipe.predict import add_extract_dims, divisible_shape
from dpipe.torch import inference_step
from kswap.batch_iter import slicewise, SPATIAL_DIMS

from kswap.utils import get_device_fold_wise
from kswap.utils import ce_plus_dice

# loss
criterion = ce_plus_dice

# model
n_filters = 16
architecture = UNet2D(n_chans_in=n_chans_in, n_chans_out=n_chans_out, n_filters_init=n_filters)

x_patch_size = y_patch_size = np.array([160, 160])
batch_size = 16

# optimizer
batches_per_epoch = 100
n_epochs = 100

lr_init = 1e-3
lr = Schedule(initial=lr_init, epoch2value_multiplier={80: 0.1, })

optimizer = torch.optim.SGD(
    architecture.parameters(),
    lr=lr_init,
    momentum=0.9,
    nesterov=True,
    weight_decay=0
)

# mapping: device <-> experiment
device = get_device_fold_wise(list_devices=[0, 1, 2, 3])


# predict
@slicewise  # 3D -> 2D iteratively
@add_extract_dims(2)  # 2D -> (4D -> predict -> 4D) -> 2D
@divisible_shape(divisor=[8] * 2, padding_values=np.min, axis=SPATIAL_DIMS[1:])
def predict(image):
    return inference_step(image, architecture=architecture, activation=torch.sigmoid)
